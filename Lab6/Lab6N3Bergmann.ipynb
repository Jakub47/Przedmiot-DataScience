{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eventlet\n",
    "import os\n",
    "import urllib.request as request\n",
    "import pandas as pd\n",
    "import regex\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Zawrzyj link do plików tesktowych gdzie kluczem będzie nazwa autora\n",
    "book_files={\n",
    " \"Mickiewicz\": [\n",
    " \"https://wolnelektury.pl/media/book/txt/pan-tadeusz.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/dziady-dziady-widowisko-czesc-i.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/dziady-dziadow-czesci-iii-ustep-do-przyjaciol-moskali.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-pani-twardowska.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-powrot-taty.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/ballady-i-romanse-switez.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/dziady-dziady-poema-dziady-czesc-iv.txt\",\n",
    " ],\n",
    " \"Sienkiewicz\": [\n",
    " \"https://wolnelektury.pl/media/book/txt/quo-vadis.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/sienkiewicz-we-mgle.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/potop-tom-pierwszy.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/potop-tom-drugi.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/potop-tom-trzeci.txt\",\n",
    " ],\n",
    " \"Orzeszkowa\": [\n",
    " \"https://wolnelektury.pl/media/book/txt/orzeszkowa-kto-winien.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-pierwszy.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-drugi.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/nad-niemnem-tom-trzeci.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/gloria-victis-dziwna-historia.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/z-pozogi.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/pani-dudkowa.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/dymy.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/syn-stolarza.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/dobra-pani.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/cnotliwi.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/kilka-slow-o-kobietach.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/patryotyzm-i-kosmopolityzm.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/julianka.txt\",\n",
    " ],\n",
    " \"Prus\": [\n",
    " \"https://wolnelektury.pl/media/book/txt/lalka-tom-drugi.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/lalka-tom-pierwszy.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/antek.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/katarynka.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/prus-anielka.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/prus-placowka.txt\",\n",
    " \n",
    " ],\n",
    " \"Reymont\": [\n",
    " \"https://wolnelektury.pl/media/book/txt/ziemia-obiecana-tom-pierwszy.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-pierwsza-jesien.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/reymont-chlopi-zima.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-trzecia-wiosna.txt\",\n",
    " \"https://wolnelektury.pl/media/book/txt/chlopi-czesc-czwarta-lato.txt\",\n",
    " ]\n",
    "}\n",
    "\n",
    "\n",
    "def fetch(url):\n",
    "    file_path = os.path.join(\"data\",os.path.basename(url))\n",
    "    if os.path.exists(file_path):\n",
    "        return None, None\n",
    "    data = request.urlopen(url).read()\n",
    "    return file_path, data\n",
    "\n",
    "#Dla każdego linku pobierz zawartość i pobierz go do folderu data\n",
    "for author in book_files:\n",
    "    pool = eventlet.GreenPool()\n",
    "    \n",
    "    for file_path, data in pool.imap(fetch, book_files[author]):\n",
    "        if file_path:\n",
    "            with open(file_path, mode=\"wb\") as f:\n",
    "                f.write(data)\n",
    "                \n",
    "\n",
    "def preprocess_file(file_path=None, file_url=None):\n",
    "    if not file_path and file_url:\n",
    "        file_path = os.path.join(\"data\",os.path.basename(file_url))\n",
    "            \n",
    "    #Pobierz zawartość plikut\n",
    "    text = open(file_path,'rb').read().decode(\"utf-8\").lower()\n",
    "    \n",
    "    text = regex.sub(u\"[^ \\n\\p{Latin}\\-'.?!]\", \" \",text) #Usuń znaki specjalne\n",
    "    text = regex.sub(u\"[ \\n]+\", \" \", text) # Usuń spacje\n",
    "    text = regex.sub(r\"----- ta lektura.*\",\"\", text) # Usuń footer zawięrający streszenie po -----\n",
    "    \n",
    "    return [regex.sub(r\"^ \",\"\",l) for l in regex.split('\\.|,|\\?|!|:',text)]\n",
    "\n",
    "\n",
    "#Zwróc w postaci data framu wartości autor : ilość lini\n",
    "def get_book_df(document, author):\n",
    "    return pd.DataFrame({\n",
    "        'author': pd.Series(len(document)*[author]),\n",
    "        'txt': pd.Series(document),\n",
    "    })\n",
    "\n",
    "#Złącz wszystkich autorów i liniami tekstów w jedną zmienną\n",
    "book_lines_df = pd.concat([\n",
    "    get_book_df(preprocess_file(file_url=url),author=author) \n",
    "        for author in book_files for url in book_files[author] \n",
    "])\n",
    "\n",
    "\n",
    "#Utwórz zestaw danych do testów i treningu\n",
    "train_df, test_df = train_test_split(\n",
    "    book_lines_df, #data frame z autorami i liniami tekstów\n",
    "    test_size=0.1, #90% treningu 10% testów\n",
    "    stratify=book_lines_df['author'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting vector for sentence 'wiedziała też o wszystkim'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x131523 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W pierwszym kroku zbudujemy słownik składający się ze wszystkich słów występujących w tekście. \n",
    "#Następnie w każdej próbce (zdaniu) przypiszemy wektor długości takiej jak liczba unikalnych słów i na każdej pozycji \n",
    "#odpowiadającej określonemu słowu umieścimy liczbę odpowiadającą ilości wystąpień danego słowa w próbce.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_df['txt']) #umieść w nim dane przeznaczone do treningu\n",
    "sample_sentence = train_df.iloc[2]['txt']\n",
    "print(\"Extracting vector for sentence '{}'\".format(sample_sentence))\n",
    "vectorizer.transform([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ragnus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ragnus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Ragnus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=True,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(train_df['txt']) #zamień nasze teksty na zbiory wektorów wejściowych\n",
    "X_test = vectorizer.transform(test_df['txt']) #zamień nasze teksty na zbiory wektorów wejściowych\n",
    "# class_weight = przypisując im wagi odwrotnie proporcjonalne do częstotliwości występowania danej klasy | dual == wykorzystanie innego sposobu implementacji algorytmu regresji logistycznej,\n",
    "model = LogisticRegression(class_weight='balanced',dual=True) \n",
    "model.fit(X_train,train_df['author']) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647394136807818"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,test_df['author']) #Sprawdzenie jakości "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Mickiewicz       0.62      0.54      0.58       509\n",
      "  Orzeszkowa       0.76      0.73      0.75      2218\n",
      "        Prus       0.74      0.73      0.74      3104\n",
      "     Reymont       0.75      0.76      0.76      2411\n",
      " Sienkiewicz       0.81      0.84      0.82      4038\n",
      "\n",
      "    accuracy                           0.76     12280\n",
      "   macro avg       0.74      0.72      0.73     12280\n",
      "weighted avg       0.76      0.76      0.76     12280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Zweryfikuj poprawność działania modelu pokazując parametry takie jak prezycja czy odwołanie\n",
    "target = test_df['author']\n",
    "predicted = model.predict(X_test)\n",
    "print(metrics.classification_report(target,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
