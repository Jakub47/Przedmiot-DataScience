{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "\n",
    "#Utwórz obiekt klasy Workbooka, a następnie utwórz 3 arkusze\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(\"Giełda\")\n",
    "ws2 = wb.create_sheet(title=\"Linki\")\n",
    "ws3 = wb.create_sheet(\"Filmweb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pod adresem https://stooq.pl/q/?s=cdr znajdziesz notowania giełdowe spółki CD Projekt Red: wygeneruj 5 losowych kodów 3-literowych ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#utworz liste która będzie posiadała pięć elementów\n",
    "listWithValues = list()\n",
    "\n",
    "while len(listWithValues) < 5:\n",
    "    threeLetters  = ''.join(random.choice(string.ascii_lowercase) for i in range(3)) #wygenreuj 3 losowe litery\n",
    "    page = requests.get(\"https://stooq.pl/q/?s=\" + threeLetters) #utworz reuqest\n",
    "    link = \"https://stooq.pl/q/?s=\" + threeLetters #zapisz link do sprawdzenia\n",
    "    soup = BeautifulSoup(page.text, 'html.parser') #utworz soup z raw textu powyższego requestu\n",
    "\n",
    "    #znajdz link jeśli istnieje oznacza to że wpsomniane 3 litery nie mają wyniki ale zawierja link do najbliższego wyszukania\n",
    "    #weź go a następnie zmień sopa na podstawie przybliżonego wyniku\n",
    "    fontWithLink = soup.find(\"font\", {\"id\": \"f16\"}) \n",
    "    if not(fontWithLink is None):\n",
    "        page = requests.get(\"https://stooq.pl/\" + fontWithLink.find('a')['href'])\n",
    "        link = \"https://stooq.pl/\" + fontWithLink.find('a')['href']\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    table = soup.find(\"table\", {\"id\": \"t1\"}) #odnajdź tabele z danymi\n",
    "    if(table is None):\n",
    "        continue #jesli jej nie mam omiń tę stronę\n",
    "    tableWithData = soup.find(\"table\", {\"id\": \"t1\"}).find('tbody') #pobierz body tabeli\n",
    "    children = tableWithData.findChildren(\"tr\" , recursive=False) #znajdź rowy tabeli\n",
    "    kurs = children[0].find('td').find('span').text \n",
    "    zmiana = children[1].find('td').find('span').text\n",
    "    liczbaTransakcji = children[6].findChildren('td')[1].find('span').text \n",
    "    listWithValues.append(kurs + \"|\" + zmiana + \"|\" + liczbaTransakcji + '|' + link) #znajdź potrzebne dane i zapisz do listy\n",
    "  \n",
    "    #do arkusza pierwszego zapisz elemnty z listy w kolumnie pierwzej od A do F\n",
    "counter = 1\n",
    "for dataValue in listWithValues:\n",
    "    cellref=ws1.cell(row=counter, column=1)\n",
    "    cellref.value=dataValue\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dla swojej ulubionej strony internetowej napisz kod, który połączy się ze stroną, znajdzie wszystkie linki na stronie (znacznik ‘a’ posiadający atrybut ‘href’), a następnie zapisze je do arkusza ‘Linki’,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jak wyżej pobierz Stronę ale tym razem korzystając z urllib\n",
    "source = urllib.request.urlopen('https://aros.pl/').read()\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "#znajdź wszystkie a a następnie zapisz do 2 kolumny 2 arkusza wszystkie linki\n",
    "aTags = soup.find_all('a')\n",
    "counter = 1\n",
    "for hhref in aTags:\n",
    "      cellref=ws2.cell(row=counter, column=2)\n",
    "      cellref.value=hhref['href']\n",
    "      counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dla ustalonego linku do filmu na Filmwebie, np. https://www.filmweb.pl/film/To%3A+Rozdzia%C5%82+2-2019-793838, napisz kod, który zwróci: reżysera,datę premiery,boxoffice,,ocenę filmu.,zapisz uzyskane wyniki do arkusza ‘Filmweb’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pobierz stronę korzystając z urllib i utwórz obiekt soup zawięrający te stronę\n",
    "source = urllib.request.urlopen('https://www.filmweb.pl/film/To%3A+Rozdzia%C5%82+2-2019-793838').read()\n",
    "soup = BeautifulSoup(source)\n",
    "mainTable = soup.find('div', attrs={'class': 'filmInfo'}) #pobierz tabele zawierającą reżyera i boxOffice a następnie go pobierz\n",
    "children = mainTable.find('table').findChildren(\"tr\" , recursive=False)\n",
    "rezyser = children[0].find('a').text\n",
    "boxOffice = children[6].find('td').text\n",
    "\n",
    "#Pobierz premiere\n",
    "RokPremiery = soup.find(\"span\", {\"class\": \"halfSize\"}).text\n",
    "#pobierz ocene\n",
    "ocena = soup.find(\"span\", itemprop=\"ratingValue\").text\n",
    "\n",
    "#Zapisz w kolumnie 3 w/w dane\n",
    "cellref=ws3.cell(row=1, column=3)\n",
    "cellref.value=rezyser\n",
    "\n",
    "cellref=ws3.cell(row=2, column=3)\n",
    "cellref.value=boxOffice\n",
    "\n",
    "cellref=ws3.cell(row=3, column=3)\n",
    "cellref.value=RokPremiery\n",
    "\n",
    "cellref=ws3.cell(row=4, column=3)\n",
    "cellref.value=ocena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save('Bergmann-165IC.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
