{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pomocny kod do bramki or i and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementacja jedno neuronowej sieci\n",
    "  \n",
    "from numpy import exp, array, random, dot, tanh \n",
    "  \n",
    "# Klasa do utworzenia sieci \n",
    "class NeuralNetwork(): \n",
    "      \n",
    "    def __init__(self,am): \n",
    "        #Używając seeda upewnij się że wygenerewoane wagi będą takie same\n",
    "        random.seed(1) \n",
    "          \n",
    "        # Matryca wag 3 na 1 \n",
    "        self.weight_matrix = 2 * random.random((am, 1)) - 1\n",
    "  \n",
    "    # funkcja aktywacji\n",
    "    def tanh(self, x): \n",
    "        return tanh(x) \n",
    "  \n",
    "    # pochodnia funkcji tanh potrzebna do policzenia gradientów\n",
    "    def tanh_derivative(self, x): \n",
    "        return 1.0 - tanh(x) ** 2\n",
    "  \n",
    "    # forward propagation  dalsza propagacja (czyli algorytm stosowany do nadzorowanego uczenia się)\n",
    "    def forward_propagation(self, inputs): \n",
    "        return self.tanh(dot(inputs, self.weight_matrix)) \n",
    "      \n",
    "    # Uczenie sieci neuronowej\n",
    "    def train(self, train_inputs, train_outputs, \n",
    "                            num_train_iterations): \n",
    "                                  \n",
    "        # Liczba iteracji, które chcemy wykonać dla tego zestawu danych wejściowych. \n",
    "        for iteration in range(num_train_iterations): \n",
    "            output = self.forward_propagation(train_inputs) \n",
    "  \n",
    "            # Oblicz błąd w danych wyjściowych.\n",
    "            error = train_outputs - output \n",
    "            #Przemnóż błąð przez dane wejściowe a następnie przez gradient wyliczonej z funkcji tanh do obliczenia dostosowania wag\n",
    "            adjustment = dot(train_inputs.T, error *\n",
    "                             self.tanh_derivative(output)) \n",
    "                               \n",
    "            #Dostosuj matryce wag\n",
    "            self.weight_matrix += adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pomocny kod do bramki XOR,XNOR,NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "#funkcja do zwrócenia sigmoid Który zwróci wartość pomiędzy 0,1 ale nigdy 0 ani 1\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#funkcja do zwrócenia pochodnej sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "#funkcja do utworzenia sieci to jest nadania wag,wag ukrytych,bias oraz do zwrócenia tablicy z wartości dla funkcji sigmoid\n",
    "def initialData(arrayDimension,input,output):\n",
    "    \n",
    "    # customowy if dla bramki not\n",
    "    if(arrayDimension == 2):\n",
    "        inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
    "    else:\n",
    "        inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 1,1,1\n",
    "        \n",
    "    #inicjalizacja z wykorzystaniem numpy do utworzenia losowych wag i bias \"dodatkowe wejście\"\n",
    "    #funkcja uniform zastosowana do równomiernego rozmiszczenia w zadanym przedziale\n",
    "    hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "    hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
    "    output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "    output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
    "    \n",
    "    #ilość epchsów czyli kro\n",
    "    epochs = 10000\n",
    "    lr = 0.1\n",
    "    \n",
    "    print(\"Inizjalizacyjne ukryte wagi: \")\n",
    "    print(hidden_weights)\n",
    "    print(\"Inizjalizacyjne ukryte biasy: \")\n",
    "    print(hidden_bias)\n",
    "    print(\"Inizjalizacyjne wyjścia wag: \")\n",
    "    print(output_weights)\n",
    "    print(\"Inizjalizacyjne wyjścia biasóws: \")\n",
    "    print(output_bias)\n",
    "    \n",
    "    #Dla każdego kroku wykonaj 1*..2*..3*..\n",
    "    for _ in range(epochs):\n",
    "        \n",
    "        #1*Propagacja do przodu\n",
    "        hidden_layer_activation = np.dot(inputs,hidden_weights)\n",
    "        hidden_layer_activation += hidden_bias\n",
    "        hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "        output_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
    "        output_layer_activation += output_bias\n",
    "        predicted_output = sigmoid(output_layer_activation)\n",
    "        \n",
    "        #2*Propagacja wsteczną\n",
    "        error = expected_output - predicted_output\n",
    "        d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "        error_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
    "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "        #3* Aktualizację wag i biasów\n",
    "        output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "        output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "        hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
    "        hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "    \n",
    "    print(\"Ostateczne wartości wag: \")\n",
    "    print(hidden_weights)\n",
    "    print(\"Ostateczne wartości biasów Final hidden bias: \")\n",
    "    print(hidden_bias)\n",
    "    print(\"Ostateczne wartości wyjściowe wag: \")\n",
    "    print(output_weights)\n",
    "    print(\"Ostateczne wartości wyjściowe biasów: \")\n",
    "    print(output_bias)\n",
    "\n",
    "    return predicted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bramka OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomowe wagi na początku treningu\n",
      "[[-0.16595599]\n",
      " [ 0.44064899]]\n",
      "\n",
      "Wartości wag po treningu\n",
      "[[5.66959122]\n",
      " [5.66958217]]\n",
      "\n",
      "DLA OR Test dla 1,0 [0.99997621]\n",
      "DLA OR Test dla 0,1 [0.9999762]\n",
      "DLA OR Test dla 1,1 [1.]\n",
      "DLA OR Test dla 0,0 [0.]\n"
     ]
    }
   ],
   "source": [
    "#Utwórz obiekt dla tablicy o wwymiarach 1x2\n",
    "neural_network = NeuralNetwork(2) \n",
    "print ('Randomowe wagi na początku treningu') \n",
    "print (neural_network.weight_matrix) \n",
    "print (\"\") \n",
    "\n",
    "#dane wejściowe dla bramki or\n",
    "train_inputs = array([[0, 0], [1, 1], [1, 0], [0, 1]]) \n",
    "#wyniki  bramki or\n",
    "train_outputs = array([[0, 1, 1, 1]]).T \n",
    "\n",
    "#Trenuj sieć\n",
    "neural_network.train(train_inputs, train_outputs, 50000) \n",
    "  \n",
    "print ('Wartości wag po treningu') \n",
    "print (neural_network.weight_matrix) \n",
    "print (\"\") \n",
    "\n",
    "print (\"DLA OR Test dla 1,0 {}\".format(neural_network.forward_propagation(array([1, 0]))))\n",
    "print (\"DLA OR Test dla 0,1 {}\".format(neural_network.forward_propagation(array([0, 1]))))\n",
    "print (\"DLA OR Test dla 1,1 {}\".format(neural_network.forward_propagation(array([1, 1]))))\n",
    "print (\"DLA OR Test dla 0,0 {}\".format(neural_network.forward_propagation(array([0, 0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bramka AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomowe wagi na początku treningu \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]]\n",
      "\n",
      "Wartości wag po treningu\n",
      "[[0.33928515]\n",
      " [0.33928515]]\n",
      "\n",
      "DLA AND Test dla 1,0 [0.32683906]\n",
      "DLA AND Test dla 0,1 [0.32683906]\n",
      "DLA AND Test dla 0,0 [0.]\n",
      "DLA AND Test dla 1,1 [0.59058916]\n"
     ]
    }
   ],
   "source": [
    "neural_network = NeuralNetwork(2) \n",
    "print ('Randomowe wagi na początku treningu ') \n",
    "print (neural_network.weight_matrix) \n",
    "print (\"\") \n",
    "  \n",
    "train_inputs = array([[0, 0], [0, 1], [1, 0], [1, 1]]) \n",
    "train_outputs = array([[0, 0, 0, 1]]).T \n",
    "  \n",
    "neural_network.train(train_inputs, train_outputs, 50000) \n",
    "  \n",
    "print ('Wartości wag po treningu') \n",
    "print (neural_network.weight_matrix) \n",
    "print (\"\") \n",
    "\n",
    "#Tutaj wartość powyżej 0,5 przybliżam do 1 a poniżej do 0\n",
    "print(\"Tutaj wartość powyżej 0,5 przybliżam do 1 a poniżej do 0\")\n",
    "print (\"DLA AND Test dla 1,0 {}\".format(neural_network.forward_propagation(array([1, 0]))))\n",
    "print (\"DLA AND Test dla 0,1 {}\".format(neural_network.forward_propagation(array([0, 1]))))\n",
    "print (\"DLA AND Test dla 0,0 {}\".format(neural_network.forward_propagation(array([0, 0]))))\n",
    "print (\"DLA AND Test dla 1,1 {}\".format(neural_network.forward_propagation(array([1, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bramka XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizjalizacyjne ukryte wagi: \n",
      "[[1.14374817e-04 3.02332573e-01]\n",
      " [1.46755891e-01 9.23385948e-02]]\n",
      "Inizjalizacyjne ukryte biasy: \n",
      "[[0.18626021 0.34556073]]\n",
      "Inizjalizacyjne wyjścia wag: \n",
      "[[0.39676747]\n",
      " [0.53881673]]\n",
      "Inizjalizacyjne wyjścia biasóws: \n",
      "[[0.41919451]]\n",
      "Ostateczne wartości wag: \n",
      "[[2.5637445  5.03970289]\n",
      " [2.56777901 5.06698699]]\n",
      "Ostateczne wartości biasów Final hidden bias: \n",
      "[[-3.82057755 -1.71878181]]\n",
      "Ostateczne wartości wyjściowe wag: \n",
      "[[-5.68712816]\n",
      " [ 5.57635717]]\n",
      "Ostateczne wartości wyjściowe biasów: \n",
      "[[-2.4985502]]\n",
      "Dla [0 0] predykcja wynosi [0.14525855]\n",
      "Dla [0 1] predykcja wynosi [0.83534545]\n",
      "Dla [1 0] predykcja wynosi [0.83519507]\n",
      "Dla [1 1] predykcja wynosi [0.19746471]\n"
     ]
    }
   ],
   "source": [
    "#Dane wejściowe i przyporządkowane dla nich wyjścia\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[0],[1],[1],[0]])\n",
    "outputToDisplay = initialData(2,inputs,expected_output)\n",
    "for index,var in enumerate(inputs):\n",
    "    print(\"Dla {} predykcja wynosi {}\".format(var,outputToDisplay[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bramka XNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizjalizacyjne ukryte wagi: \n",
      "[[0.6852195  0.20445225]\n",
      " [0.87811744 0.02738759]]\n",
      "Inizjalizacyjne ukryte biasy: \n",
      "[[0.67046751 0.4173048 ]]\n",
      "Inizjalizacyjne wyjścia wag: \n",
      "[[0.55868983]\n",
      " [0.14038694]]\n",
      "Inizjalizacyjne wyjścia biasóws: \n",
      "[[0.19810149]]\n",
      "Ostateczne wartości wag: \n",
      "[[5.78130969 3.61545682]\n",
      " [5.74968321 3.60932   ]]\n",
      "Ostateczne wartości biasów Final hidden bias: \n",
      "[[-2.38833952 -5.52837456]]\n",
      "Ostateczne wartości wyjściowe wag: \n",
      "[[-7.34372679]\n",
      " [ 7.98831643]]\n",
      "Ostateczne wartości wyjściowe biasów: \n",
      "[[3.29078998]]\n",
      "\n",
      " Odpowiedź od sieci po 10000 krokach: \n",
      "Dla [0 0] predykcja wynosi [0.93731647]\n",
      "Dla [0 1] predykcja wynosi [0.058175]\n",
      "Dla [1 0] predykcja wynosi [0.05806921]\n",
      "Dla [1 1] predykcja wynosi [0.93692936]\n"
     ]
    }
   ],
   "source": [
    "#Dane wejściowe i przyporządkowane dla nich wyjścia\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "expected_output = np.array([[1],[0],[0],[1]])\n",
    "outputToDisplay = initialData(2,inputs,expected_output)\n",
    "print(\"\\n Odpowiedź od sieci po 10000 krokach: \")\n",
    "for index,var in enumerate(inputs):\n",
    "    print(\"Dla {} predykcja wynosi {}\".format(var,outputToDisplay[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bramka NOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizjalizacyjne ukryte wagi: \n",
      "[[0.80074457]]\n",
      "Inizjalizacyjne ukryte biasy: \n",
      "[[0.96826158]]\n",
      "Inizjalizacyjne wyjścia wag: \n",
      "[[0.31342418]]\n",
      "Inizjalizacyjne wyjścia biasóws: \n",
      "[[0.69232262]]\n",
      "Ostateczne wartości wag: \n",
      "[[5.33115028]]\n",
      "Ostateczne wartości biasów Final hidden bias: \n",
      "[[-2.62078268]]\n",
      "Ostateczne wartości wyjściowe wag: \n",
      "[[-7.146818]]\n",
      "Ostateczne wartości wyjściowe biasów: \n",
      "[[3.50034306]]\n",
      "\n",
      "Odpowiedź od sieci po 10000 krokach: \n",
      "Dla [0] predykcja wynosi [0.95327527]\n",
      "Dla [1] predykcja wynosi [0.03913936]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[0],[1]])\n",
    "expected_output = np.array([[1],[0]])\n",
    "outputToDisplay = initialData(1,inputs,expected_output)\n",
    "print(\"\\nOdpowiedź od sieci po 10000 krokach: \")\n",
    "for index,var in enumerate(inputs):\n",
    "    print(\"Dla {} predykcja wynosi {}\".format(var,outputToDisplay[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
